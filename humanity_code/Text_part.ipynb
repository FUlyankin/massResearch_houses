{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35109"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.read_csv('cian_data_v1.csv', sep='\\t')\n",
    "y = dff[\"цена\"].values\n",
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35109"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f =  open('description_lemm.txt', \"r\")\n",
    "T = f.readlines()\n",
    "f.close()\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее качество: -25127349.84829654\n",
      "Лучшие параметры: {'regressor__alpha': 0.01} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('regressor',\n",
       "                 ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True,\n",
       "                            l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                            positive=False, precompute=False, random_state=None,\n",
       "                            selection='cyclic', tol=0.0001,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_train, T_test, y_train, y_test = train_test_split(T_lemm, y, test_size = 0.2)\n",
    "\n",
    "grid_search_size=1000\n",
    "\n",
    "vectorizer = TfidfVectorizer( ) # (min_df=10, max_df=0.8)#, max_features=4000)\n",
    "regressor = ElasticNet()\n",
    "    \n",
    "pipe = Pipeline(steps=[('vectorizer', vectorizer),\n",
    "                       ('regressor', regressor)])\n",
    "\n",
    "parameters = dict(#vectorizer__min_df=np.arange(0,12,2),\n",
    "#                   regressor__alpha=np.logspace(-4, 4, 50),\n",
    "    regressor__alpha=np.logspace(-4, 4, 5)\n",
    "#                   regressor__l1_ratio=[0, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n",
    "                 )\n",
    "\n",
    "gridcv = GridSearchCV(pipe, parameters, scoring='neg_mean_absolute_error', cv=5, n_jobs=- 1)\n",
    "\n",
    "if y_train.size <= grid_search_size:\n",
    "    y_gs = y_train\n",
    "    T_gs = T_train\n",
    "else:\n",
    "    T_gs, _, y_gs, _ = train_test_split(T_train, y_train, \n",
    "                                        test_size=(1 - grid_search_size/y_train.size), \n",
    "                                        random_state=42)\n",
    "    \n",
    "gridcv.fit(T_gs, y_gs)\n",
    "\n",
    "print('Лучшее качество: {}'.format(gridcv.best_score_))\n",
    "print('Лучшие параметры:', gridcv.best_params_, '\\n')\n",
    "\n",
    "model = gridcv.best_estimator_\n",
    "model.fit(T_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.890105035907485"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(model.predict(T_test) - y_test))/10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from W2vVecorizer import W2vVecorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w2v_models/w2v_Ivan/word2index.pickle\", \"rb\") as f:\n",
    "    word2index = pickle.load(f)\n",
    "    \n",
    "embedding = np.load(\"w2v_models/w2v_Ivan/embedding.npy\")\n",
    "\n",
    "vectorzer = W2vVecorizer(word2index, embedding)\n",
    "vectorzer.fit(T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985072603468474"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorzer.nice_cnt/vectorzer.all_cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28087, 300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_vect = vectorzer.transform(T_train)\n",
    "T_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
