{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для копаний со случайным лесом и его особенностями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деревья и леса\n",
    "\n",
    "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits['data']\n",
    "y = digits['target']\n",
    "print X\n",
    "print y\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.__ Создайте `DecisionTreeClassifier` с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эта величина и будет ответом в пункте 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree_base_classif = tree.DecisionTreeClassifier( )\n",
    "tree_base_classif.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "tree_scoring = cross_val_score(tree_base_classif, X, y, scoring = 'accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tree_scoring\n",
    "print tree_scoring.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100.\n",
    "\n",
    "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "bg_classifier = ensemble.BaggingClassifier(base_estimator = tree_base_classif, n_estimators = 100)\n",
    "bg_classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_scoring = cross_val_score(bg_classifier, X, y, scoring = 'accuracy', cv = 10)\n",
    "print bg_scoring\n",
    "print bg_scoring.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех $d$ признаках, а на $\\sqrt{d}$ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sqrtd_classifier = ensemble.BaggingClassifier(base_estimator = tree_base_classif, \n",
    "                                                 n_estimators = 100, max_features = 8)\n",
    "\n",
    "bg_sqrtd_scoring = cross_val_score(bg_sqrtd_classifier, X, y, scoring = 'accuracy', cv = 10)\n",
    "print bg_sqrtd_scoring\n",
    "print bg_sqrtd_scoring.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же $\\sqrt{d}$ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_base_classif = tree.DecisionTreeClassifier(max_features = 'sqrt')\n",
    "\n",
    "bg_sqrtd_classifier = ensemble.BaggingClassifier(base_estimator = tree_base_classif, \n",
    "                                                 n_estimators = 100)\n",
    "\n",
    "bg_sqrtd_scoring = cross_val_score(bg_sqrtd_classifier, X, y, scoring = 'accuracy', cv = 10)\n",
    "print bg_sqrtd_scoring\n",
    "print bg_sqrtd_scoring.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. \n",
    "\n",
    "Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "rf_classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scoring = cross_val_score(rf_classifier, X, y, scoring = 'accuracy', cv = 10)\n",
    "print rf_scoring\n",
    "print rf_scoring.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)\n",
    "\n",
    "1) Случайный лес сильно переобучается с ростом количества деревьев\n",
    "\n",
    "2) При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
    "\n",
    "3) С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "\n",
    "4) При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "\n",
    "5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "\n",
    "6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "\n",
    "7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга).\n",
    "\n",
    "\n",
    "Правильные утверждения:  2,3,4,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про кросс-валидацию по числу деревьев\n",
    "\n",
    "Теперь подберём число деревьев (*n_estimators*) в алгоритме RandomForest. Как известно, в общем случае Random Forest не переобучается с увеличением количества деревьев. Подберите количество деревьев, начиная с которого качество на кросс-валидации стабилизируется. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев: обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества деревьев разных размеров, состоящие из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте найденное количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# создаём объект, в котором будет лежать разбиение индексов на фолды\n",
    "kf = KFold(n_splits=5, random_state=s)\n",
    "\n",
    "# Обучаем пять лесов, по одному для каждого фолда :3 \n",
    "rfs = [ ]\n",
    "for train,test in kf.split(y):\n",
    "    clf_rf = ensemble.RandomForestClassifier(random_state=s, n_estimators=1000)\n",
    "    clf_rf.fit(X_real[train],y[train])\n",
    "    rfs.append(clf_rf)\n",
    "\n",
    "\n",
    "def find_roc_auc(i_fold, X, y):\n",
    "    \"\"\"\n",
    "        Находит по номеру фолда 1000 последовательных рок ауков\n",
    "        На каждой итерации увеличиаваем число деревьев в лесу на одно\n",
    "    \"\"\"\n",
    "    roc_auc = [ ] # сюда будем записывать пятёрки чисел \n",
    "\n",
    "    # сюда будем записывать предсказания каждого дерева\n",
    "    predictions = [ ]\n",
    "\n",
    "    # запоминаем тестовые индексы \n",
    "    test_ind = list(kf.split(y))[i_fold][-1]\n",
    "    for tree in rfs[i_fold].estimators_:\n",
    "        predictions.append(tree.predict(X[test_ind]))\n",
    "\n",
    "    # делаем прогнозы нумпаевской матрицей\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # кумулятивная сумма прогнозов \n",
    "    Z_sum = np.cumsum(predictions,axis=0) \n",
    "\n",
    "    # число деревьев, которое на данной итерации принимает решение\n",
    "    Z_cnt = np.ones(predictions.shape)*np.arange(1,predictions.shape[0] + 1, 1).reshape(predictions.shape[0], 1)\n",
    "\n",
    "    # Кумулятивной среднее (Вероятность быть отнесённым к классу 1)\n",
    "    Z_mean = Z_sum/Z_cnt\n",
    "\n",
    "    # считаем roc-auc для каждого числа деревьев \n",
    "    roc_auc = [ ]\n",
    "    for row in Z_mean:\n",
    "        roc_auc.append(roc_auc_score(y[test_ind], row))\n",
    "    return roc_auc\n",
    "\n",
    "# Матрица из roc_auc. По строчкам фолды, по столбцам качество при ансамбле из j деревьев\n",
    "ROC = np.array([find_roc_auc(i_fold, X_real, y) for i_fold in range(5)])\n",
    "\n",
    "# находим по фолдам средний roc-auc и дисперсию\n",
    "rc_mean = ROC.mean(axis=0)\n",
    "rc_std = ROC.std(axis=0)\n",
    "\n",
    "num = np.arange(1,1001,1)\n",
    "plt.plot(num, rc_mean)\n",
    "plt.fill_between(num, rc_mean-2*rc_std, rc_mean+2*rc_std, alpha=0.2, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
