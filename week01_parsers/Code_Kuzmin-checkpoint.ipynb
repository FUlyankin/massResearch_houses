{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наш любимый парсер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from lxml.html import fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем ссылку для парсера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(params):\n",
    "    main_page = 'https://www.cian.ru/cat.php?'\n",
    "    params_1 = 'engine_version=2&deal_type=sale&offer_type=flat'\n",
    "    params_2 = '&district={district}&{room}&region={region}&object_type={objt}'.format(**params)\n",
    "    return main_page + params_1 + params_2\n",
    "\n",
    "params = {\n",
    "    'region': 1,\n",
    "    'district': 1,\n",
    "    'room': 'room1=1',\n",
    "    'objt': 1}\n",
    "\n",
    "\n",
    "districts = [1, 325, 326, 4, 5, 6, 7, 8, 9, 10, 11, 151]\n",
    "\n",
    "rooms = ['room1=1', 'room2=1', 'room3=1', 'room4=1', \n",
    "         'room5=1', 'room6=1', 'room7=1', 'room9=1']\n",
    "\n",
    "objt = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_urls = [ ]\n",
    "\n",
    "for rm in rooms:\n",
    "    for ob in objt:\n",
    "        params = {\n",
    "            'region': 1,\n",
    "            'district': 4,\n",
    "            'room': rm,\n",
    "            'objt': ob}    \n",
    "        main_urls.append(create_url(params))\n",
    "            \n",
    "len(main_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_capcha(soup):\n",
    "    if soup.title.text == 'Captcha - база объявлений ЦИАН':\n",
    "        print(\"Вылезла сраная капча!\")\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existence(soup):\n",
    "    if soup.find('h3', {'class' : '_93444fe79c--banner-text-bold--gDIvc'}) == []:\n",
    "        print('Такого сайта нет')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hrefs(url, p):\n",
    "    MAX_RETRIES = 10\n",
    "    url = url +'&p={}'.format(p)\n",
    "    \n",
    "    session = requests.Session()\n",
    "    adapter = requests.adapters.HTTPAdapter(max_retries=MAX_RETRIES)\n",
    "    session.mount('https://', adapter)\n",
    "    session.mount('http://', adapter)\n",
    "    \n",
    "    resp = session.get(url)\n",
    "    print(resp.status_code)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "    \n",
    "    existence = check_existence(soup)\n",
    "    #сделать так, чтобы не читал после класса _93444fe79c--title--299uA\n",
    "    s = soup.find_all('div', {'class' : '_93444fe79c--card--_yguQ'})\n",
    "    hrefs = [(url, item.find('a', {'class' : 'c6e8ba5398--header--1fV2A'}).get('href')) for item in s]\n",
    "    return hrefs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, p):  \n",
    "    \n",
    "    url = url + '&p={}'.format(p)\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "    return soup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            #Grabbing IP and corresponding PORT\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'‪C:\\Users\\Admin\\Desktop\\gekodriver\\geckodriver.exe'\n",
    "#subprocess.call(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from selenium import webdriver #веселый кулхацкинг\n",
    "\n",
    "#driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proxies = get_proxies()\n",
    "hrefs_dict = {}\n",
    "hrefs = []\n",
    "i = 0\n",
    "\n",
    "for url in tqdm_notebook(main_urls):\n",
    "    for p in range(1, 55):\n",
    "        i += 1\n",
    "        try:\n",
    "            soup = get_soup(url, p)\n",
    "        except ConnectionError:\n",
    "            print(\"Конекшн эрор\")\n",
    "            time.sleep(30)\n",
    "            soup = get_soup(url, p)\n",
    "        while check_capcha(soup) == True:\n",
    "            time.sleep(900)\n",
    "            soup = get_soup(url, p)\n",
    "        \n",
    "        cur_hrefs = get_hrefs(url, p)\n",
    "        if p > 1:\n",
    "            try:\n",
    "                if cur_hrefs[0] == hrefs[-1]:\n",
    "                    break\n",
    "            except IndexError:\n",
    "                break\n",
    "        hrefs.extend(cur_hrefs)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hrefs_dict = defaultdict(list)\n",
    "for url, href in hrefs:\n",
    "    hrefs_dict[url].append(href)\n",
    "\n",
    "print(hrefs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = set(hrefs)\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'C:\\Users\\Admin\\Desktop\\Учеба\\масс рисёрч\\massResearch_houses\\massResearch_houses\\week01_parsers\\CAO.pickle', 'wb') as f:\n",
    "    pickle.dump(hrefs_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\u202aCAO.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-071ab12e7e9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'‪CAO.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mfirst_18_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfirst_18_iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\u202aCAO.pickle'"
     ]
    }
   ],
   "source": [
    "with open('‪CAO.pickle', 'rb') as f:\n",
    "    first_18_iterations = pickle.load(f)\n",
    "first_18_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(soup)):\n",
    "    resp = requests.get(soup[i])\n",
    "    soups = BeautifulSoup(resp.content)\n",
    "    price = soups.find_all(\"span\", {\"itemprop\": \"price\"})[0]\n",
    "    price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.sub('\\D', '', price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = get_proxies()\n",
    "proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
