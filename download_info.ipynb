{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Вытаскиваем ссылки, которые накачали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# модуль с мелкими функциями для части информации\n",
    "from cian_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hrefs_total.pickle', 'rb') as f:\n",
    "    hrefs_total = pickle.load(f)\n",
    "    \n",
    "len(hrefs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hrefs_total), len(set(hrefs_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтобы включать ТОР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socks\n",
    "import socket\n",
    "socks.set_default_proxy(socks.SOCKS5, \"localhost\", 9150)\n",
    "socket.socket = socks.socksocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIP():\n",
    "    ip = requests.get('http://checkip.dyndns.org').content\n",
    "    soup = BeautifulSoup(ip, 'html.parser')\n",
    "    print(soup.find('body').text)\n",
    "\n",
    "checkIP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Качаем основную информацию по квартирам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем всё в одну функцию! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infa_download(soup):\n",
    "    infa_dict = {}\n",
    "    infa_dict.update(get_general_information(soup))\n",
    "    infa_dict.update(get_about(soup))\n",
    "    infa_dict.update(get_price(soup))\n",
    "    infa_dict.update(get_description(soup))\n",
    "    infa_dict.update(get_square_info(soup))\n",
    "    infa_dict.update(get_address(soup))\n",
    "    infa_dict.update(get_metro(soup))\n",
    "    infa_dict.update(get_title(soup))\n",
    "    infa_dict.update(get_coord(soup))\n",
    "    return infa_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной цикл: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_infa = [ ] # для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "for url in tqdm_notebook(hrefs_total):  # качаю для первого десятка ссылок\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        soup = get_soup(url)\n",
    "    except ConnectionError:\n",
    "        print('конэкшон ерор')\n",
    "        time.sleep(10)\n",
    "        soup = cian.get_soup(url)\n",
    "    \n",
    "    if soup.find(\"div\", {\"data-name\": \"OfferUnpublished\"}):\n",
    "        print('объявление снято')\n",
    "        continue\n",
    "        \n",
    "    cur_infa = infa_download(soup)\n",
    "    all_infa.append(cur_infa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_real.index(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_infa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранялка. Сохраняем в формате `info_2000_5000.pickle`, где цифры означают с какого по какой файл скачали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# осторожнее с именами файлов! случайно можно перезаписать готовый :( \n",
    "with open('data/info_0_10.pickle', 'wb') as f:\n",
    "    pickle.dump(hrefs_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно проверить всё ли ок сохранилось\n",
    "with open('data/info_0_10.pickle', 'rb') as f:\n",
    "    data_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поглазеть на данные: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_infa)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
